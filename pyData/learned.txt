From my work with the PyData stack, I've learned quite a few things. In terms of the California Housing Dataset (which is the dataset I chose to analyze), my main discoveries so far from my matplotlib and seaborn plots are probably that the AveRooms and AveBedrms variables are strongly correlated (which is expected) and that the MedInc and MedHouseVal variables seem to have strict cutoffs after certain points, where all values higher get rounded down (for example, it appears to be 5.00001 for MedHouseVal). I noticed this since my histograms had weird spikes on the right. 

In terms of working with the PyData stack, I've enjoyed playing around with and Googling how to do things I want to do, such as finding a best fit line in numpy for a scatter plot (specifically AveRooms vs AveBedrms), slicing a pandas DataFrame in either direction, or how to check if any values in a DataFrame are null. I've also realized that I don't fully understand how DataFrames actually behave (like why is df[['HouseAge','MedInc']]) allowed), so that's on my list of lingering questions among other things, like what plt is actually doing (like why plt.scatter() then plt.show, what are each of these things "actually" doing).

In terms of working with Jupyter notebooks, I've really loved the workflow and started adding some custom keyboard shortcuts ('a', 'b', and 'dd' in command mode are great, I've added 'Alt+Up/Down' to move blocks up and down, for example). I also played with adding a custom.js file so I could have some extra keybinds in edit mode (e.g. 'Alt+Shift+Down' in order to duplicate lines, a useful feature in other text editors). I'm hoping to play around more with this, and maybe even add my own custom.css file.

On the Boston Housing Dataset: Having a "B" column for "Black proportion of the population" is already potentially racially discriminatory (if used incorrectly, I could imagine a malicious person being able to affect housing prices of black neighborhoods negatively using this data and a model). Nonetheless, this probably not the main issue with the dataset; after all, data is data and, as mentioned in the article, "The potential to point out systemic imbalance between populations, and offer an avenue to investigate potential discriminatory practices which lead to and sustain such imbalance, is also present in this data." The main problem is the quadratic non-invertible function applied to the original data, which assumes, for example, that 0.36 and 0.90 black populations behave identically. This is *destroying data*, and could be hiding something. In addition, the quadratic function pushes the model towards concluding that racial self-segregation may be beneficial towards housing prices. Even if this is true in the data, it should be included in the model, not the raw data itself. I think the dataset would still be valuable for education purposes, but only for a meta-lesson on datasets and data. I think if we wanted an actual study about how race affects housing prices, we would definitely need a dataset with the original data of black proportion of population without any non-invertible function applied to it.